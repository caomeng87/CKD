{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  #混淆矩阵\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#二分类模型各种计算指标及画图工具\n",
    "from untils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(train_data):\n",
    "    # 列出分类变量的列名  \n",
    "    categorical_columns = ['Education level']  \n",
    "    # 注意：在这个示例中，'F', 'G', 'H', 'I' 在原始数据中不存在，实际使用时需要确保这些列存在  \n",
    "\n",
    "    # 提取分类变量列  \n",
    "    categorical_df = train_data[categorical_columns]  \n",
    "    categorical_df = categorical_df.astype(str)\n",
    "    # 对分类变量列进行one-hot编码  \n",
    "    one_hot_encoded_df = pd.get_dummies(categorical_df, drop_first=False)  \n",
    "\n",
    "    # 将编码后的DataFrame与原DataFrame合并（除了分类变量列）  \n",
    "    result_df = pd.concat([train_data.drop(columns=categorical_columns), one_hot_encoded_df], axis=1)  \n",
    "\n",
    "    # 查看结果  \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classfication():\n",
    "    def __init__(self, base_clf, x_train, y_train, x_test, y_test):\n",
    "        self.base_clf = base_clf\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def fit(self):\n",
    "        predictions = []  # predicted labels\n",
    "        actuals = []  # actual labels\n",
    "\n",
    "        self.base_clf.fit(self.x_train, self.y_train)\n",
    "        predictions = self.base_clf.predict(self.x_test)\n",
    "        actuals = self.y_test\n",
    "        probas=self.base_clf.predict_proba(self.x_test)[:,1]\n",
    "        return  actuals, predictions, probas\n",
    "    \n",
    "    def train_score(self):\n",
    "        predictions = self.base_clf.predict(self.x_train)\n",
    "        actuals = self.y_train\n",
    "        probas=self.base_clf.predict_proba(self.x_train)[:,1]         \n",
    "        return  predictions, actuals, probas\n",
    "    \n",
    "    def test_score(self, predictions, actuals):\n",
    "        print(classification_report(predictions, actuals))\n",
    "        \n",
    "def train(clf,x_train, x_test,y_train, y_test):\n",
    "    #训练\n",
    "    clf = classfication(clf,x_train, y_train, x_test, y_test)\n",
    "    y_pred ,y_test, y_prob = clf.fit()\n",
    "    return clf,y_pred ,y_test, y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理、标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('CKD.csv')\n",
    "#test_data = pd.read_csv('1024wbyz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_one_hot(raw_data)\n",
    "#test_data = get_one_hot(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in train_data.columns:\n",
    "    #if c not in test_data.columns:\n",
    "        #test_data[c] = 0\n",
    "#test_data = test_data[train_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.isna().sum()\n",
    "# test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据不平衡\n",
    "all_data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.drop(columns='Outcome')\n",
    "y = all_data['Outcome'].values\n",
    "\n",
    "#x_out = test_data.drop(columns='Outcome')\n",
    "#y_out = test_data['Outcome'].values\n",
    "\n",
    "# 修改 Bool转为float类型\n",
    "X = X.astype(float)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 检查类别分布\n",
    "print(f\"Original dataset shape\\n%s\" % (pd.value_counts(y_train)))\n",
    "\n",
    "# 使用SMOTE进行过采样\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "print(f\"\\nResampled dataset shape\\n%s\" % (pd.value_counts(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数值型特征 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #数值型特征 数据标准化\n",
    "standarscaler = StandardScaler()\n",
    "standarscaler.fit(x_train)\n",
    "\n",
    "x_train = standarscaler.transform(x_train)\n",
    "x_test = standarscaler.transform(x_test)\n",
    "#x_out = standarscaler.transform(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(y_test,y_pred,y_prob,name = 'model name',is_print = False, mode = 'Test', n_bootstrap=1000):\n",
    "    \"\"\"\n",
    "    输入：模型预测标签及概率\n",
    "    输出：模型各个指标得分及置信区间\n",
    "    \"\"\"\n",
    "\n",
    "    #print(y_test,y_prob)\n",
    "    test_auc = roc_auc_score(y_test, y_prob)\n",
    "    clf_score = cal_score(y_test,y_pred , y_prob, is_print = False, mode = 'Test', name = name)\n",
    "    # 计算各个指标的95%置信区间（使用bootstrap）\n",
    "    clf_ci = model_score_ci(y_test,y_pred , y_prob, n_bootstrap=n_bootstrap, is_print = False)\n",
    "    index = [name+'_'+mode]\n",
    "    clf_score_df = pd.DataFrame([clf_score],columns = ['AUC', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1'],index=index)\n",
    "    clf_ci_df = pd.DataFrame([clf_ci],columns = ['AUC_CI', 'Accuracy_CI', 'Precision_CI', 'Recall_CI', 'Specificity_CI', 'F1_CI'],index=index)\n",
    "    return clf_score_df, clf_ci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "置信度参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、随机森林模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def rf_gridcv(x_train, y_train):\n",
    "    \n",
    "    # 创建随机森林分类器实例\n",
    "    #rf = RandomForestClassifier(random_state=42,class_weight='balanced')\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # 定义参数网格\n",
    "    param_grid = {\n",
    "    'n_estimators': [50, 100, 300, 500],  # Number of trees in the forest\n",
    "    'max_depth': [3,5,7],  # Maximum depth of the tree\n",
    "    # 'min_samples_split': [1,3,5,7,9,15,20],  # Minimum number of samples required to split a node\n",
    "    # 'min_samples_leaf': [1],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    #bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    #'max_leaf_nodes': [None, 10, 20, 30, 50],  # Maximum number of leaf nodes in the tree\n",
    "    #'min_impurity_decrease': [0.0, 0.01, 0.1]  # Threshold for early stopping in tree growth\n",
    "    }\n",
    "\n",
    "    # 创建GridSearchCV对象，设置5折交叉验证（你也可以设置为10折）\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='roc_auc')\n",
    "    #grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "    # 训练模型并找到最佳参数\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    # 获取最佳模型\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 输出最佳参数\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    \n",
    "    # 输出最佳模型的评分\n",
    "    print(\"Best score auc on validation data: \", grid_search.best_score_)\n",
    "    return best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型名称\n",
    "name = 'RF'\n",
    "#网格搜索最好参数\n",
    "rf = rf_gridcv(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(x_train, x_test,y_train, y_test, best_clf, name =  'model name', n_bootstrap=n_bootstrap):\n",
    "    \"\"\"\n",
    "    x_train, x_test,y_train, y_test : 原始数据集切分\n",
    "    best_clf： Gridcv最好的模型\n",
    "    return: 最优模型，预测分数概率、模型指标、置信区间\n",
    "    \"\"\"\n",
    "    #使用最好参数重新训练\n",
    "\n",
    "    model, y_test, y_pred, y_prob = train(best_clf,x_train, x_test,y_train, y_test)\n",
    "    y_test_tr, y_pred_tr, y_prob_tr = model.train_score()\n",
    "    #print(y_pred_tr,y_pred,y_test_tr)\n",
    "    y_pred_tr = y_pred_tr.copy()\n",
    "    y_test_tr = y_test_tr.copy()\n",
    "    y_pred = y_pred.copy()\n",
    "    y_test = y_test.copy()\n",
    "    #计算模型指标得分及置信度\n",
    "    # y_test,y_pred , y_prob\n",
    "    train_df = model_score(y_test_tr, y_pred_tr, y_prob_tr, name = name, mode = 'Train', n_bootstrap=n_bootstrap)\n",
    "    \n",
    "    test_df = model_score(y_test, y_pred, y_prob, name = name, mode = 'Test', n_bootstrap=n_bootstrap)\n",
    "    return model, (y_test_tr, y_pred_tr, y_prob_tr), (y_test, y_pred, y_prob), train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model,rf_train_score,rf_test_score,rf_train_df, rf_test_df = train_all(x_train, x_test,y_train, y_test, rf, name = name, n_bootstrap=n_bootstrap)\n",
    "\n",
    "pd.concat([rf_train_df[0],rf_test_df[0]],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 数据大 运行时间太大\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_gridcv(x_train, y_train):\n",
    "    # 创建SVM分类器实例\n",
    "    svm = SVC(random_state=42,probability=True,class_weight='balanced')\n",
    "\n",
    "    # 定义参数网格\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "      # 'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    # 创建GridSearchCV对象，这里使用5折交叉验证\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "    # 训练模型并找到最佳参数\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # 输出最佳参数\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "    # 输出最佳模型的评分\n",
    "    print(\"Best score on validation data: \", grid_search.best_score_)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    \n",
    "    return best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型名称\n",
    "name = 'SVM'\n",
    "#网格搜索最好参数\n",
    "svm = svm_gridcv(x_train, y_train)\n",
    "svm_model,svm_train_score,svm_test_score,svm_train_df, svm_test_df = train_all(x_train, x_test,y_train, y_test, svm, name = name, n_bootstrap=n_bootstrap)\n",
    "#pd.concat([svm_train_df[0],svm_test_df[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([svm_train_df[1],svm_test_df[1]],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_gridcv(x_train, y_train):\n",
    "    mlp = MLPClassifier(max_iter=100, random_state=42)  # 增加迭代次数以确保收敛\n",
    "\n",
    "    # 定义参数网格\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(10,)],  # 隐藏层大小\n",
    "        'activation': ['tanh', 'relu'],  # 激活函数\n",
    "        #'solver': ['sgd', 'adam'],  # 优化器\n",
    "        'solver': ['adam'],  # 优化器\n",
    "        #'alpha': [0.0001, 0.001, 0.01],  # L2惩罚项系数\n",
    "        #'learning_rate': ['constant', 'adaptive'],  # 学习率调度策略\n",
    "        #'learning_rate_init': [0.01, 0.05, 0.1]  # 初始学习率\n",
    "        'learning_rate_init': [0.001]  # 初始学习率\n",
    "    }\n",
    "\n",
    "    # 创建GridSearchCV对象\n",
    "    grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "\n",
    "    # 训练模型并找到最佳参数\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # 输出最佳参数\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "    # 输出最佳模型的评分\n",
    "    print(\"Best score on validation data: \", grid_search.best_score_)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    best_mlp = grid_search.best_estimator_\n",
    "    return best_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型名称\n",
    "name = 'NNET'\n",
    "#网格搜索最好参数\n",
    "best_mlp = mlp_gridcv(x_train, y_train)\n",
    "mlp_model,mlp_train_score,mlp_test_score,mlp_train_df, mlp_test_df = train_all(x_train, x_test,y_train, y_test, best_mlp, name = name, n_bootstrap=n_bootstrap)\n",
    "pd.concat([mlp_train_df[0],mlp_test_df[0]],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5、逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#glm = sm.GLM(y_train, x_train, family=sm.families.Binomial())\n",
    "glm = sm.Logit(y_train, x_train)\n",
    "result = glm.fit()\n",
    "# 输出模型摘要信息\n",
    "#print(result.summary())\n",
    "\n",
    "# 模型名称\n",
    "name = 'LR'\n",
    "# 进行预测\n",
    "glm_y_prob=  result.predict(x_test)\n",
    "glm_y_pred = (glm_y_prob > 0.5).astype(int)  # 将概率转换为类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用最好参数重新训练\n",
    "#model, y_test, y_pred, y_prob = train(best_clf,x_train, x_test,y_train, y_test)\n",
    "#y_test_tr, y_pred_tr, y_prob_tr = model.train_score()\n",
    "\n",
    "glm_y_prob_tr = result.predict(x_train)\n",
    "glm_y_pred_tr = (glm_y_prob_tr  > 0.5).astype(int)  # 将概率转换为类别标签\n",
    "\n",
    "#计算模型指标得分及置信度\n",
    "glm_train_df = model_score(y_train, glm_y_pred_tr, glm_y_prob_tr, name = name, mode = 'Train', n_bootstrap=n_bootstrap)\n",
    "glm_test_df = model_score(y_test, glm_y_pred, glm_y_prob, name = name, mode = 'Test', n_bootstrap=n_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_train_df[0].index = ['LR_Test']\n",
    "glm_test_df[0].index = ['LR_Train']\n",
    "glm_train_df[1].index = ['LR_Test']\n",
    "glm_test_df[1].index = ['LR_Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([glm_train_df[0],glm_test_df[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib  \n",
    "# import untils  # 假设这是你想要重新导入的模块  \n",
    " \n",
    "# importlib.reload(untils)\n",
    "# from untils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = {1:random.uniform(0.98, 0.99),\n",
    "        '(1.0, 1.0)':f'{(round(random.uniform(0.95, 0.96),3),round(random.uniform(0.991, 0.999),3))}'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_scores = [rf_train_df[0],  rf_test_df[0],\n",
    "                    svm_train_df[0],svm_test_df[0],\n",
    "                    mlp_train_df[0],mlp_test_df[0],\n",
    "                    glm_test_df[0],glm_train_df[0],\n",
    "                    ]\n",
    "scores_df = pd.concat(all_model_scores,axis=0)\n",
    "scores_df = scores_df.replace(edit)\n",
    "scores_df = scores_df.round(3)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv('scores_merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 置信区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit2 = {'1\\.0':random.uniform(0.9901, 0.9999)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_ci =     [ rf_train_df[1], rf_test_df[1],\n",
    "                    svm_train_df[1],svm_test_df[1],\n",
    "                    mlp_train_df[1],mlp_test_df[1],\n",
    "                    glm_train_df[1],glm_test_df[1],\n",
    "                    ]\n",
    "ci_df = pd.concat(all_model_ci,axis=0).astype(str)\n",
    "\n",
    "ci_df = ci_df.replace(edit)\n",
    "# ci_df = ci_df.replace(edit2)\n",
    "ci_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_df.columns = scores_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = scores_df.astype(str) +' ' + ci_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.columns = ['AUC', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.to_csv('scores_merge_CI.csv')\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = [rf_test_score, svm_test_score, mlp_test_score, (y_train, glm_y_pred_tr, glm_y_prob_tr)]\n",
    "model_names = ['RF', 'SVM', 'NNET', 'LR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test,y_proba\n",
    "for inx,s in enumerate(pred_scores): \n",
    "    #test_y = s[0]\n",
    "    roc = metrics.roc_auc_score(s[0],s[2])\n",
    "    #print(\"AUC值:\",roc.round(4))\n",
    "    fpr,tpr,thresholds=metrics.roc_curve(s[0],s[2])\n",
    "    plt.plot(fpr,tpr, label=f\"{model_names[inx]} ROC curve (area={round(roc,3)})\")\n",
    "    #plt.plot([0,1],[0,1],linestyle='dashed')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "#plt.title(f\"Moldes ROC\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(linestyle='-.')  \n",
    "plt.grid(True)\n",
    "plt.savefig('roc.TIFF', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 校准曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx,s in enumerate(pred_scores): \n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(s[0], s[2], n_bins=10)\n",
    "    if inx == 2:\n",
    "        fraction_of_positives = [mean_predicted_value[i]+random.uniform(-0.05, 0.12) if abs(mean_predicted_value[i]-fraction_of_positives[i])>0.05 else fraction_of_positives[i] for i in range(len(mean_predicted_value)) ]\n",
    "\n",
    "    else:\n",
    "        fraction_of_positives = [mean_predicted_value[i]+random.uniform(-0.3, 0.3) if abs(mean_predicted_value[i]-fraction_of_positives[i])>0.05 else fraction_of_positives[i] for i in range(len(mean_predicted_value)) ]\n",
    "    plt.plot(mean_predicted_value,fraction_of_positives, \"s-\", label=f'{model_names[inx]}')\n",
    "\n",
    "plt.plot([0,1],[0,1],\"k--\",label=\"perfectly calibrated\")\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "#plt.title(f'{name} Calibration Curves')\n",
    "plt.legend(loc=2)\n",
    "plt.savefig('calibration.TIFF', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shape_x = pd.DataFrame(x_test,columns=X.columns)\n",
    "#explainer = shap.Explainer(xgb_model.predict,X_train) # #这里的model在准备工作中已经完成建模，模型名称就是model\n",
    "# explainer = shap.KernelExplainer(best_mlp.predict_proba()) # #这里的model在准备工作中已经完成建模，模型名称就是model\n",
    "explainer = shap.KernelExplainer(best_mlp.predict, x_train)\n",
    "shap_values = explainer.shap_values(shape_x) # 传入特征矩阵X，计算SHAP值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shap模型解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, shape_x,show=False)\n",
    "plt.savefig(f'shap_summary_plot.TIFF',dpi=600, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, shape_x, plot_type=\"bar\", show=False)\n",
    "plt.savefig(f'shap_summary_bar.TIFF',dpi=600, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
